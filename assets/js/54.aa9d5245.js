(window.webpackJsonp=window.webpackJsonp||[]).push([[54],{366:function(e,a,n){"use strict";n.r(a);var t=n(7),o=Object(t.a)({},(function(){var e=this,a=e._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("p",[a("img",{attrs:{src:"https://b3logfile.com/bing/20191130.jpg?imageView2/1/w/960/h/540/interlace/1/q/100",alt:""}})]),e._v(" "),a("p",[e._v("1.摘要")]),e._v(" "),a("p",[e._v("本文简要概述了Kafka的由来，并详细说明了Kafka的架构和设计原则。在充分了解了Kafka相关原理的基础上，尝试使用虚拟机搭建了一个单机多实例的Kafka及其所需的Zookeeper集群。最后在已有集群基础上整合Spring Boot,构建了一个简易的Kafka使用用例。\n2.研究现状\n近年来,随着信息技术与互联网应用的不断发展,全球数据总量也在呈现爆炸式的增长,大数据时代即将来临[1]。任何大型互联网公司都会产生大量的“日志”数据，如社交网站中登录、浏览、点击、喜欢、分享、评论以及网络服务本身的调用栈、调用延迟、错误报告以及一些机器运行指标数据。这些数据被越来越多的用到线上业务，实现诸如基于数据驱动的推荐、广告精准投放的功能。传统的企业级消息系统如activemq，IBM Websphere MQ，Oracle Enterprise Messaging Service，TIBCO Enterprise Message Service已经存在很长时间了，主要作用是消息总线和异步解耦，但它们并不能无缝适配以上的需求。Apache Kafka起源于LinkedIn，后来于2011年成为Apache开源项目，然后于2012年成为Apache项目的第一个类别。它是使用Scala和Java编写的。Apache Kafka,作为一种分布式的消息系统,具有可水平扩展和高吞吐率而被广泛的使用[2]。\n3.Kafka的概念体系和架构\n3.1主要概念和术语\n数据源,在用户行为分析中主要是指移动端日志和web日志[3]。一个日志记录也称为记录或消息。当向Kafka读取或写入数据时，将以事件的形式进行操作。从概念上讲，事件具有键、值、时间戳和可选的元数据标题。下面是一个示例事件：事件的键：“张三”，事件的值：“向李四支付了200元”，事件发生的时间戳记录：“2020年11月29日，下午2:06”。\n生产者是那些向Kafka发布事件的客户端应用程序，而消费者是那些订阅即读取和处理这些事件的客户端应用程序。在Kafka中，生产者和消费者之间完全脱钩且彼此不可知，由此Kafka实现了高可伸缩性。在传统应用开发中，服务之间通过HTTP和RPC调用实现通信，造成服务之间存在高耦合、请求易阻塞以及请求无缓冲等缺陷。特别是业务逻辑越发复杂，所需服务数量越多。随着服务规模的不断扩张以及服务请求量的急剧增加,这些缺陷也被不断地放大从而影响着整个系统的性能和稳定性[4]。\nKafka中的主题始终是多生产者和多用户的：一个主题可以有零个，一个或多个向其写入事件的生产者，以及零个，一个或多个订阅这些事件的使用者。可以根据需要随时读取主题中的事件-与传统的消息传递系统不同，使用后事件不会被删除。相反，您可以通过按主题配置设置来定义Kafka将事件保留多长时间，之后旧的事件将被丢弃。Kafka的性能相对于数据大小实际上是恒定的，因此长时间存储数据是非常好的。\n主题分区，这意味着主题分布在位于不同Kafka Broker上的多个存储单元中。数据的这种分布式放置对于可伸缩性非常重要，因为它允许客户端应用程序同时从多个Broker读取数据或向多个Broker写入数据。将新事件发布到主题时，实际上会将其附加到主题的分区之一。具有相同事件密钥，例如，客户ID或车辆ID的事件被写入相同的分区，并且Kafka保证，给定主题分区的任何使用者都将始终以与写入时完全相同的顺序读取该分区的事件。\n为了使数据具有容错性和高可用性，在地理区域或数据中心之间，可以复制每个主题，因此，总是有多个代理可以复制数据，以防万一出错。常见的生产设置中复制因子为3，也就是始终会有三个数据副本。复制将在主题分区级别执行。\n3.2架构体系\nKafka的架构图（使用ProcessOn绘制导出png格式）如下：")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-b6d0162e.png",alt:"image.png"}})]),e._v(" "),a("p",[e._v("Kafka架构图\nBroker: Kafka作为一个或多个服务器的集群运行，可以跨越多个数据中心或云区域。其中一些服务器构成了存储层，称为代理。其他服务器运行 Kafka Connect来连续导入和导出数据作为事件流，以将Kafka与现有系统集成在一起，例如关系数据库以及其他Kafka群集。为了实现关键任务用例，Kafka群集具有高度的可扩展性和容错能力：如果其任何服务器发生故障，其他服务器将接管其工作，以确保连续运行而不会丢失任何数据。\nConsumer/Producer: 用户可以编写分布式应用程序和微服务，即使在网络问题或机器故障的情况下，也可以并行，大规模且以容错的方式读取，写入和处理事件流。Kafka附带了一些这样的客户端，由Kafka社区提供的数十个客户端进行了扩展 ：客户端可用于Java和Scala，包括更高级别的 Kafka Streams库，Go，Python，C / C ++和许多其他编程语言以及REST API。\nTopic:相当于传统消息系统MQ中的一个队列queue，producer端发送的message必须指定是发送到哪个topic上.在一个大型的应用系统中，可以根据功能的不同，区分不同的topic(订单的topic,登录的topic,金额的topic等等)\nPartition: 为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体（多个partition间）的顺序。\n4.Kafka的设计原则\n4.1存储设计\nKafka依赖于文件系统来存储和缓存消息。一个主题的每个分区就是逻辑上的一段消息集合。具体到物理上，为了防止分区文件过大，Kafka会将其进一步分成数据段。每次数据往最新的数据段中写，写到设定容量后，就会新建一个段文件继续写。此外，为了提高写入性能，Kafka会将事件记录在内存中进行缓存，只有事件数量达到设定值或者缓存数据的大小达到设定值时，才会将数据写入外存中。为了保证可靠性，只有数据已写入外存后，才会将其通知给消费者。\n和传统的消息系统不同，Kafka在设计时采用了文件追加的方式来写入消息，即只能在段文件的尾部追加新的消息，并且也不允许修改己写入的消息，这种方式属于典型的顺序写盘的操作，顺序写磁盘的速度要比随机写内存的速度更块。每个消费者总是顺序的去消费每个分区的数据。创建topic时，Kafka为该topic的每个分区在文件系统中创建一个对应的子目录，名字就是"),a("topic",[e._v('-<分区号>。所以倘若有一个topic名为test，有两个分区，那么在文件系统中kafka会创建两个子目录：test-0和test-1。每个日志子目录的文件都是由若干组分段构成。每个分段中的日志文件以log后缀都有两个对应的索引文件：偏移量索引文件（".index"后缀）和时间戳索引文件（以".timeindex"为后缀）。这些索引文件帮助Broker更快的定位消息所在的物理文件位置。\n4.2传输设计\n网络传输是比较消耗时间和系统资源的，因此Kafka在网络传输的设计采取了较多的优化。生产者可以批量传输数据到Broker,消费者虽然看起来是逐条消费的，但在API实现的底层也是批量拉取一定大小的消息供消费者消费。Kafka在操作系统层面使用页缓存加快磁盘读写，在传统上，一条数据从本地文件送到socket上通常包含以下几个过程：\n(1)从外存中读入数据到操作系统的页缓存。\n(2)从页缓存拷贝数据到应用缓冲区中。\n(3)从应用缓冲区拷贝到内核缓冲区。\n(4)从内核缓冲区拷贝到socket。\n这些过程涉及四次数据拷贝和两次系统调用，非常浪费资源。在Linux操作系统中，存在一个sendfile 零拷贝技术的API，能够直接将数据从文件传送到socket中。利用此API，可以省去步骤(2)(3)中引入的两次数据拷贝和一次系统调用，由此使得Kafka可以将数据从Broker的段文件中高效的传输给消费者，极大提高了系统性能。\n4.3无状态的Broker\n与其他消息队列不同，Kafka的Broker仅提供基于offset的读取方式，不会维护各个消费者当前已消费消息的offset值，而是由消费者各自维护当前读取的进度。消费者读取数据时告诉Broker请求消息的起始offset值，Broker将之后的消息流式发送过去。从而使Broker的设计可以相对简化，不用维护过多状态。但是这样做也存在一些问题，Broker不知道消费者消费到了哪里，也就不知道哪些消息需要被清理。对此，Kafka使用了一个简单的策略，对消息设定有效期，每个主题可以设置不同的有效期。这个简单的策略适用于绝大多数情况。大量存储和拉取的设计带来的另外一个重要的好处是消费者可以主动选择进行回退消费。这个需求看起来违背了通常消息队列的定义，然而在很多情况下却非常有必要。举例来说，当消费者进程由于错误而挂掉后，可以在恢复后有选择的对挂掉前后的数据重新消费。这对将ETL数据导入Hadoop等数据仓库之类的场景非常重要。但是对于Kafka来说，消费者只需要记住消费到的offset即可，下次重启后再从该offset后开始拉取。但是对于传统没有大量缓存的消息队列来说，可能这部分数据就永远的丢了。\n4.4分布式协调一致\n多个生产者和消费者在分布式环境中的行为，对于生产者，其发送数据时，可以将其随机发送到一个分区所在Broker；也可以根据key以及作用于key上的路由函数，将其发送到某特定分区机器Broker上。对于消费者,行为稍复杂。\n在Kafka中，多个消费者或消费者实例可以组成一个消费者组。它们共享一个公共的ID，即group ID，组内的所有消费者协调在一起来消费订阅主题的所有分区。对于消费者组的理解需要明白三点：一.消费者组下可以有一个或多个消费者实例，消费者实例可以是一个进程，也可以是一个线程。二是组ID是一个字符串，唯一标识一个消费者组。三是消费组下订阅的主题的每个分区只能分配给组内一个消费者。\nKafka引入了一个高可用的一致性服务Zookeeper。Zookeeper的API很像文件系统，是以前缀树的形式组织的KV也就是键值对，K键是路径，以’/’来区分层次，V值可以是任何可序列化的值存储。该API支持创建一个路径、给一个路径设置值、读取路径的值、删除一个路径、列出某个路径下所有子节点的值。此外，Zookeeper还具有以下特性：\n(1)客户端可以向某个路径注册一个回调函数，以监听该路径的值或其孩子节点的变动。\n(2)路径可以被创建为易失的，即当所有该路径的客户端消失后，该路径及值会被自动的移除。\n(3) Zookeeper使用一致性协议将其数据进行多机备份，使其服务具有高可靠性和高可用性。\nKafka使用Zookeeper完成以下几个任务：\n(1)监控Brokers和消费者的增删。\n(2)当出现Brokers或者消费者的增删时，启动消费再平衡任务。\n(3)维护消费者的间关系状态，跟踪每个分区的消费偏移量。\n具体来说，代理和消费者会将自身元信息注册到Zookeeper的注册表中，其中包括：代理的主机名、端口以及在其上的主题和分区。每个消费者组都在Zookeeper中有一个相关联的所有权注册表和偏移量注册表。我们将消费者消费某个分区的行为称为占有，所有权注册表即记录了消费者与其占有的分区间的对应关系。其中，路径名标识一个分区，记录值是该分区的拥有者。偏移量记录表记录了该消费者组所有订阅的 topic 对应的每个分区的消费进度。\n当一个新的消费者组创建时，注册表中没有任何的偏移量记录。这时，使用Broker提供的 API，该消费者组可以针对每个分区选择从最小的偏移量或者最大的偏移量进行消费。\n4.5数据交付保证\nKafka提供3种消息传输一致性语义：最多1次，最少1次，恰好1次。最少1次：可能会重传数据，有可能出现数据被重复处理的情况;最多1次：可能会出现数据丢失情况;\n恰好1次：并不是指真正只传输1次，只不过有一个机制。确保不会出现“数据被重复处理”和“数据丢失”的情况。\nKafka保证来自于同一个分区的消息是保序的，即offset大小顺序，但是不同分区之间的顺序是不保证的。\n5.Kafka特性与安全\n面向存储的消息队列：意味在近实时的情况下能够将传统消息队列的存储增加几个数量级。实现原理是充分利用了磁盘的顺序写和操作系统自身的缓存；此外为了提高访盘、传输效率，使用了文件分段、段首索引、零拷贝和批量拉取等技术。\n灵活的生产消费方式：基于主题粒度的发布订阅式架构，并且既支持组内多消费者互斥消费，也支持不同消费者组间的重复消费。这里面涉及到消息队列的两个设计选择：pull式消费以及客户端侧存储消费进度。为了简化实现，消费时，每个分区最多为一个消费者所消费。\nZookeeper存储元信息：利用分布式一致性组件Zookeeper以注册表的形式存储系统元信息，包括Broker和消费者的存活信息、消费者和分区间的对应关系、每个分区的消费进度等等。Zookeeper作为一个前缀树形式组织KV、支持发布订阅的高可用组件，可以满足 Kafka进行消费协调和进度保存的协作需求。\n简洁强大的消费接口：Kafka的客户端一般提供两层接口抽象。包括无需关注分区和偏移量信息的高层（high-level）简单读写接口，以及可以灵活控制分区组织和消费进度的低层（low-level）接口。\n随着越来越多的安全漏洞、数据泄露等问题的爆发,安全正成为系统选型不得不考虑的问题,Kafka由于其安全机制的匮乏,也导致其在数据敏感行业的部署存在严重的安全隐患[5]。在拥有强大性能的同时，Kafka在安全方面的问题需要在实际部署应用时特别注意，以免造成生产事故。\n6.应用场景\nKafka有着丰富的使用场景并且已经得到了广泛而深入的应用。例如：在证券交易所，银行和保险中，用于实时处理付款和金融交易。在物流和汽车行业，实时跟踪和监视汽车，卡车，车队和货运。在物联网应用中，连续捕获和分析来自IoT设备或其他设备（例如工厂和风电场）中的传感器数据。在零售，酒店和旅游行业以及移动应用程序中，收集并立即响应客户的交互和订单。监测患者的医院护理情况并预测病情变化，以确保在紧急情况下及时得到治疗。还可以连接，存储和提供公司不同部门产生的数据，用作数据平台，事件驱动的体系结构和微服务的基础。\n7.使用示例\n7.1搭建Kafka和Zookeeper单机多实例环境\n本测试环境使用Linux操作系统环境，发行版本为CentOS-7-x86_64-Minimal-1908，虚拟化软件为VMware Workstation Pro。为虚拟机分配1GB内存，硬盘容量20GB，使用NAT模式联网，实体机与虚拟机器在同一网段下，可以相互访问，为后续本机访问虚拟机中的Kafka集群提供网络基础条件。\n(1)\t搭建虚拟机环境，配置虚拟机静态IP。')])],1),e._v(" "),a("p",[e._v("配置Linux主机网卡设置静态IP：vim /etc/sysconfig/network-script/ifcfg-ens33,保存配置后重启网络：systemctl restart network，以下是配置详单。\nTYPE=Ethernet\nPROXY_METHOD=none\nBROWSER_ONLY=no\nBOOTPROTO=static\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPADDR=192.168.10.12\nNETMASK=255.255.255.0\nGATEWAY=192.168.10.2\nDNS1=114.114.114.114\nDNS2=8.8.8.8\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nIPV6_ADDR_GEN_MODE=stable-privacy\nNAME=ens33\nUUID=30da6508-90d0-4643-8f65-efa88eec2481\nDEVICE=ens33\nONBOOT=yes")]),e._v(" "),a("p",[e._v("(2)\t获取Zookeeper安装包 wget https://xxx/apache-zookeeper-3.6.2-bin.tar.gz\n(3)解压安装包 tar –zxvf apache-zookeeper-3.6.2-bin.tar.gz\n(4)修改配置文件 zoox.cfg,参考如下：\ntickTime=2000\ninitLimit=10\nsyncLimit=5\ndataDir=/opt/data/zookeeper/zkserver1\nclientPort=2181\nserver.1=127.0.0.1:2888:3888\nserver.2=127.0.0.1:2889:3889\nserver.3=127.0.0.1:2890:3890\n其中dataDir设置三个配置文件写三个不同的目录，事先创建好,在每个目录下创建myid文件写入数字序号，例如第一个实例写入1。clienPort每个实例各不相同，server.x各个端口不能相同，因为我们是单机运行多个实例。\n(5)运行Zookeeper 在其目录里执行命令：\nbin/zkServer.sh start conf/zoox.cfg\n(6)执行 netstat –ntpl查看是否程序监听相应端口\n(7)获取Kafka安装包\nwget https://xxx/kafka_2.13-2.6.0.tgz\n(8)解压\ntar –zxvf kafka_2.13-2.6.0.tgz\n(9)修改配置文件\nvim config/serverx.properties  需修改的配置：\nbroker.id=1\nlisteners=PLAINTEXT://192.168.10.12:9091\nlog.dir=/opt/data/kafka/server1\nzookeeper.connect=127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183\n(10)启动三个Kafka实例，在其目录中执行\nbin/kafka-server-start.sh –daemon config/serverx.properties")]),e._v(" "),a("p",[e._v("(11)运行jps,检查zookeeper和kafka服务是否正常运行。\n7.2 Spring Boot整合Kafka使用用例\n使用IDEA新建Spring Boot项目，勾选Spring Boot整合Kafka的依赖库，maven文件截图如下：\n新建类KafkaProducer作为一个Controller。")]),e._v(" "),a("p",[e._v("创建方法saycallback接受用户get请求并设置路径参数，将值作为消息发送到Kafka集群的topic1主题下，注册回调函数用于处理发送结果。\n新建类KafkaConsumer用于消费Kafka集群中的消息。使用@Component注解标识此类为组件，此类中有一个KafkaTemplate类型的属性，该属性值由spring自动注入，对象的构造由kafka支持库自动读取配置文件完成构建。spring将注入此消费者类到IOC容器。\n在类中创建方法getMessage3接受消息并打印，由注解@KafkaListener可知消费者的id为consumer2，消费者组id为consumer-group2，消费的主题为topic1。通过注解@KafkaListener可以指定消费的主题，分区以及初始偏移值，也可以指定消费多个\n主题。")]),e._v(" "),a("p",[e._v("以下为示例代码和配置文件截图：")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-91d3e964.png",alt:"image.png"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-6c89b927.png",alt:"image.png"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-0ab00e48.png",alt:"image.png"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-de8b4682.png",alt:"image.png"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-5449c714.png",alt:"image.png"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-001a59cf.png",alt:"image.png"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-5a7b065e.png",alt:"image.png"}})]),e._v(" "),a("p",[e._v("环境搭建截图：")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-9d52169f.png",alt:"image.png"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-cd78e2db.png",alt:"image.png"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-b896f80f.png",alt:"image.png"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-0c5adef0.png",alt:"image.png"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-a8210bbc.png",alt:"image.png"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-6f163233.png",alt:"image.png"}})]),e._v(" "),a("p",[e._v("以下是运行结果截图：")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-2e6e9aea.png",alt:"image.png"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-46cfcc07.png",alt:"image.png"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://b3logfile.com/file/2021/01/image-64d0611d.png",alt:"image.png"}})]),e._v(" "),a("p",[e._v("8.参考文献\n[1]牛牧. 基于Kafka的大规模流数据分布式缓存与分析平台[D].吉林大学,2016.\n[2]王岩,王纯.一种基于Kafka的可靠的Consumer的设计方案[J].软件,2016,37(01):61-66.\n[3]费秀宏. 基于Kafka的日志处理平台的研究[D].吉林大学,2017.\n[4]卢帅. 基于Kafka的消息发布订阅服务的设计与实现[D].南京大学,2018.\n[5]孙元浩.如何构建安全的Kafka集群[J].电信网技术,2015(08):10-14.")])])}),[],!1,null,null,null);a.default=o.exports}}]);