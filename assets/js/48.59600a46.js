(window.webpackJsonp=window.webpackJsonp||[]).push([[48],{360:function(a,e,t){"use strict";t.r(e);var _=t(7),v=Object(_.a)({},(function(){var a=this,e=a._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("p",[e("img",{attrs:{src:"https://b3logfile.com/bing/20200320.jpg?imageView2/1/w/960/h/540/interlace/1/q/100",alt:""}})]),a._v(" "),e("h4",{attrs:{id:"hdfs中的block、packet、chunk"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#hdfs中的block、packet、chunk"}},[a._v("#")]),a._v(" HDFS中的block、packet、chunk")]),a._v(" "),e("p",[a._v("block")]),a._v(" "),e("p",[a._v("文件上传前需要分块，每个块就是一个block，一般一个block为128MB，可以修改，但不推荐。")]),a._v(" "),e("p",[a._v("packet")]),a._v(" "),e("p",[a._v("packet是第二大的单位，它是client端向DataNode，或DataNode的PipLine之间传数据的基本单位，默认64KB。")]),a._v(" "),e("p",[a._v("chunk")]),a._v(" "),e("p",[a._v("chunk是最小的单位，它是client向DataNode，或DataNode的PipLine之间进行数据校验的基本单位，默认512Byte，因为用作校验，故每个chunk需要带有4Byte的校验位。所以实际每个chunk写入packet的大小为516Byte。由此可见真实数据与校验值数据的比值约为128 : 1。（即64*1024 / 512）")]),a._v(" "),e("p",[a._v("例如，在client端向DataNode传数据的时候，HDFSOutputStream会有一个chunk buff，写满一个chunk后，会计算校验和并写入当前的chunk。之后再把带有校验和的chunk写入packet，当一个packet写满后，packet会进入dataQueue队列，其他的DataNode就是从这个dataQueue获取client端上传的数据并存储的。同时一个DataNode成功存储一个packet后之后会返回一个ack packet，放入ack Queue中。")]),a._v(" "),e("h4",{attrs:{id:"hdfs写流程"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#hdfs写流程"}},[a._v("#")]),a._v(" HDFS写流程")]),a._v(" "),e("p",[a._v("写详细步骤：")]),a._v(" "),e("p",[a._v("1.客户端向NameNode发出写文件请求。")]),a._v(" "),e("p",[a._v("2.检查是否已存在文件、检查权限。若通过检查，先将操作写入EditLog，并返回输出流对象。")]),a._v(" "),e("p",[a._v("（注：WAL，write ahead\nlog，先写Log，再写内存，因为EditLog记录的是最新的HDFS客户端执行所有的写操作。如果后续真实写操作失败了，由于在真实写操作之前，操作就被写入EditLog中了，故EditLog中仍会有记录，我们不用担心后续client读不到相应的数据块，因为在第5步中DataNode收到块后会有一返回确认信息，若没写成功，发送端没收到确认信息，会一直重试，直到成功）")]),a._v(" "),e("p",[a._v("3.client端按128MB的块切分文件。")]),a._v(" "),e("p",[a._v("4.client将NameNode返回的分配的可写的DataNode列表和Data数据一同发送给最近的第一个DataNode节点，此后client端和NameNode分配的多个DataNode构成pipeline管道，client端向输出流对象中写数据。client每向第一个DataNode写入一个packet，这个packet便会直接在pipeline里传给第二个、第三个…DataNode。")]),a._v(" "),e("p",[a._v("（注：并不是写好一个块或一整个文件后才向后分发）")]),a._v(" "),e("p",[a._v("5.每个DataNode写完一个块后，会返回确认信息。")]),a._v(" "),e("p",[a._v("（注：并不是每写完一个packet后就返回确认信息，因为packet中的每个chunk都携带校验信息，没必要每写一个就汇报一下，这样效率太慢。正确的做法是写完一个block块后，对校验信息进行汇总分析，就能得出是否有块写错的情况发生）")]),a._v(" "),e("p",[a._v("6.写完数据，关闭输输出流。")]),a._v(" "),e("p",[a._v("7.发送完成信号给NameNode。")]),a._v(" "),e("p",[a._v("（注：发送完成信号的时机取决于集群是强一致性还是最终一致性，强一致性则需要所有DataNode写完后才向NameNode汇报。最终一致性则其中任意一个DataNode写完后就能单独向NameNode汇报，HDFS一般情况下都是强调强一致性）")]),a._v(" "),e("h4",{attrs:{id:"hdfs读流程"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#hdfs读流程"}},[a._v("#")]),a._v(" HDFS读流程")]),a._v(" "),e("p",[a._v("读相对于写，简单一些")]),a._v(" "),e("p",[a._v("读详细步骤：")]),a._v(" "),e("p",[a._v("1.client访问NameNode，查询元数据信息，获得这个文件的数据块位置列表，返回输入流对象。")]),a._v(" "),e("p",[a._v("2.就近挑选一台datanode服务器，请求建立输入流。")]),a._v(" "),e("p",[a._v("3.DataNode向输入流中中写数据，以packet为单位来校验。")]),a._v(" "),e("p",[a._v("4.关闭输入流")]),a._v(" "),e("h4",{attrs:{id:"读写过程-数据完整性如何保持"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#读写过程-数据完整性如何保持"}},[a._v("#")]),a._v(" 读写过程，数据完整性如何保持")]),a._v(" "),e("p",[a._v("通过校验和。因为每个chunk中都有一个校验位，一个个chunk构成packet，一个个packet最终形成block，故可在block上求校验和。")]),a._v(" "),e("p",[a._v("HDFS 的client端即实现了对 HDFS 文件内容的校验和 (checksum) 检查。当客户端创建一个新的HDFS文件时候，分块后会计算这个文件每个数据块的校验和，此校验和会以一个隐藏文件形式保存在同一个 HDFS 命名空间下。当client端从HDFS中读取文件内容后，它会检查分块时候计算出的校验和（隐藏文件里）和读取到的文件块中校验和是否匹配，如果不匹配，客户端可以选择从其他 Datanode 获取该数据块的副本。")]),a._v(" "),e("p",[a._v("HDFS中文件块目录结构具体格式如下：")]),a._v(" "),e("p",[a._v("${dfs.datanode.data.dir}/")]),a._v(" "),e("p",[a._v("├── current")]),a._v(" "),e("p",[a._v("│ ├── BP-526805057-127.0.0.1-1411980876842")]),a._v(" "),e("p",[a._v("│ │ └── current")]),a._v(" "),e("p",[a._v("│ │ ├── VERSION")]),a._v(" "),e("p",[a._v("│ │ ├── finalized")]),a._v(" "),e("p",[a._v("│ │ │ ├── blk_1073741825")]),a._v(" "),e("p",[a._v("│ │ │ ├── blk_1073741825_1001.meta")]),a._v(" "),e("p",[a._v("│ │ │ ├── blk_1073741826")]),a._v(" "),e("p",[a._v("│ │ │ └── blk_1073741826_1002.meta")]),a._v(" "),e("p",[a._v("│ │ └── rbw")]),a._v(" "),e("p",[a._v("│ └── VERSION")]),a._v(" "),e("p",[a._v("└── in_use.lock")]),a._v(" "),e("p",[a._v("in_use.lock表示DataNode正在对文件夹进行操作")]),a._v(" "),e("p",[a._v("rbw是“replica being\nwritten”的意思，该目录用于存储用户当前正在写入的数据。")]),a._v(" "),e("p",[a._v("Block元数据文件（*.meta）由一个包含版本、类型信息的头文件和一系列校验值组成。校验和也正是存在其中。")]),a._v(" "),e("p",[a._v("这是以前自己学习时摘抄网上的内容记录在word里的，今天看到就直接复制贴到博客上了，如有冒犯，敬请留言，我将及时删除。")])])}),[],!1,null,null,null);e.default=v.exports}}]);